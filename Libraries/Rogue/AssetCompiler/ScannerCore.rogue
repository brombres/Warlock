library AssetCompiler

# Generated by Froley. WARNING: WILL BE OVERWRITTEN.

$include "CompileError.rogue"
$include "ScanTable.rogue"
$include "Token.rogue"
$include "TokenType.rogue"

class ScannerCore [abstract]
  DEFINITIONS
    ip_main = 0
    ip_tokenize_value = 1
    ip_consume_ws = 2
    ip_create_identifier = 3
    ip_scan_id_term_or_keyword = 4
    ip_create_id_or_keyword = 5
    ip_scan_number = 6
    ip_scan_integer = 7
    ip_scan_string = 8

  PROPERTIES
    _filepath     : String
    _scanner      : Rogue::Scanner
    line          = 1
    column        = 1

    tokens        : Token[]
    buffer        = String()
    output        = String()

    start_ip      = 0
    halt          = false

    _position_stack  = Int[]
    _line_stack      = Int[]
    _column_stack    = Int[]
    _token_pos_stack = Int[]

    # GENERATED PROPERTIES
    ch : Character
    _scan_pattern_0 = ScanPattern( "[^\n]*" )
    _scan_pattern_1 = ScanPattern( "[^ \t\n\\]]*" )
    _scan_pattern_2 = ScanPattern( "[ \r\t]*" )
    _scan_pattern_3 = ScanPattern( "{[_a-zA-Z][_a-zA-Z0-9]*}" )
    _scan_pattern_4 = ScanPattern( "[^ \t\n]*" )
    _scan_pattern_5 = ScanPattern( "[0-9]" )
    _scan_pattern_6 = ScanPattern( "[0-9]*" )
    _scan_table_0 = ScanTable("Lv8LKhhAGikcXR46ID0iLSQoJlsoKyovLAAAAQACAAMABAAFAAYABwAIAAkACgA=")
    _scan_table_1 = ScanTable("gR4ABGUKZlBnZnN4/wFuDv8BZBL/AkcYUyr/AXIc/wFvIP8BdST/AXAoAQD/AXQu/wFhMv8Bbjb/AWQ6/wFhPv8BbEL/AW9G/wFuSv8BZU4CAP8Bb1T/AWxY/wFkXP8BZWD/AXJkAwD/AXJq/wFvbv8BdXL/AXB2BAD/AXR8/wFhgQD/AW6BBP8BZIEI/wFhgQz/AWyBEP8Bb4EU/wFugRj/AWWBHAUA")

  METHODS
    method init
      noAction

    method init( file:File, line=1, column=1 )
      init( file.filepath, Rogue::Scanner(file).[line=line, column=column] )

    method init( filepath:String, content:String, line=1, column=1 )
      init( filepath, Rogue::Scanner(content).[line=line, column=column] )

    method init( _filepath, _scanner, line=1, column=1 )
      noAction

    method reset
      if (_scanner) _scanner.reset
      line   = 1
      column = 1
      tokens = null
      buffer.clear
      output.clear
      start_ip = 0
      halt = false
      _position_stack.clear
      _line_stack.clear
      _column_stack.clear
      _token_pos_stack.clear

    method reset( file:File, line=1:Int, column=1:Int )
      reset
      init( file, line, column )

    method reset( filepath:String, content:String, line=1:Int, column=1:Int )
      reset
      init( filepath, content, line, column )

    method execute( ip:Int )
      _clear_state
      _execute( ip )

    method tokenize( file:File, line=1, column=1, &ip=null:Int? )->Token[]
      return tokenize( file.filepath, Rogue::Scanner(file) )

    method tokenize( filepath:String, content:String, line=1, column=1, &ip=null:Int? )->Token[]
      return tokenize( filepath, Rogue::Scanner(content).[line=line, column=column] )

    method tokenize( _filepath, _scanner, line=1, column=1, &ip=null:Int? )->Token[]
      reset
      return tokenize( ip )

    method tokenize( ip=null:Int? )->Token[]
      tokens = Token[]
      if (ip) start_ip = ip.value
      _clear_state
      while (_execute(start_ip) or not halt)
        buffer.clear
      endWhile
      _on_output_line # flush any buffered output
      return tokens

    method _add( type:TokenType )
      if (type.attributes & TokenType.ATTRIBUTE_CONTENT)
        tokens.add( _t(type,buffer.cloned) )
      else
        tokens.add( _t(type) )
      endIf
      buffer.clear

    method _clear_state
      tokens = Token[]
      buffer.clear
      output.clear
      halt = false

    method _describe_character( c:Character )->String
      if (c == 10 or c == 13)       return "end of line";
      elseIf (c >= 32 and c != 127) return "'$'" (c)
      else                          return "'$'" (c.to_escaped_ascii)

    method _discard_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "discardPosition without prior savePosition." )
      endIf
      _position_stack.remove_last
      _line_stack.remove_last
      _column_stack.remove_last
      _token_pos_stack.remove_last

    method _is_next( text:String )->Logical
      local location = _scanner.location
      local result = _scanner.consume( text )
      _scanner.location = location
      return result

    method _must_consume( ch:Character )
      if (_scanner.consume(ch)) return
      local message = "Syntax error - expected $, found " (_describe_character(ch))
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _must_consume( st:String )
      if (_scanner.consume(st)) return
      _throw_expected_string_error( "'$'" (st.to_escaped_ascii("'")) )

    method _must_consume( pattern:ScanPattern )
      if (pattern.scan(_scanner)) return
      _throw_expected_string_error( pattern->String )

    method _next_is( text:String )->Logical
      if (not _scanner.has_another(text.count)) return false
      local pos = _scanner.position
      forEach (ch at index in text)
        if (ch != _scanner.data[pos+index]) return false
      endForEach
      return true

    method _on_output_line
      # Default behavior: print out 'output' and clear it. Can override this method.
      print( output )
      flush
      output.clear

    method _restore_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "restorePosition without prior savePosition." )
      endIf
      _scanner.position = _position_stack.remove_last
      _scanner.line     = _line_stack.remove_last
      _scanner.column   = _column_stack.remove_last
      tokens.discard_from( _token_pos_stack.remove_last )

    method _save_position
      _position_stack.add( _scanner.position )
      _line_stack.add( _scanner.line )
      _column_stack.add( _scanner.column )
      _token_pos_stack.add( tokens.count )

    method _scan( ch:Character )->Logical
      if (not _scanner.consume(ch)) return false
      buffer.print ch
      return true

    method _scan( text:String )->Logical
      if (not _scanner.consume(text)) return false
      buffer.print text
      return true

    method _t( type:TokenType, content=null:String )->Token
      return Token( type, _filepath, _scanner.source, line, column, content )

    method _throw_expected_string_error( st:String )
      local message = "Syntax error - expected $, found " (st)
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _throw_syntax_error( message=null:String )
      if (not message)
        local builder = String()
        builder.print "Syntax error - unexpected "
        if (not _scanner.has_another)
          builder.println "end of input."
        else
          builder.[ print(_describe_character(_scanner.peek)), print('.') ]
        endIf
        message = builder
      endIf
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _execute( ip:Int )->Logical
      which (ip)
        case ip_main: return r_main
        case ip_tokenize_value: return r_tokenize_value
        case ip_consume_ws: return r_consume_ws
        case ip_create_identifier: return r_create_identifier
        case ip_scan_id_term_or_keyword: return r_scan_id_term_or_keyword
        case ip_create_id_or_keyword: return r_create_id_or_keyword
        case ip_scan_number: return r_scan_number
        case ip_scan_integer: return r_scan_integer
        case ip_scan_string: return r_scan_string
        others
          halt = true
          return false
      endWhich

    method r_main->Logical
      if (not r_consume_ws) return false
      if ((not _scanner.has_another))
        halt = true
        return false
      endIf
      line   = _scanner.line
      column = _scanner.column
      if (_scanner.consume('\n'))
        _add( TokenType.EOL )
        return false
      endIf
      if (_scanner.consume("#"))
        _scan_pattern_0.scan(_scanner,buffer)
        _add( TokenType.COMMENT )
        return false
      endIf
      if (_scanner.consume('['))
        _add( TokenType.SYMBOL_OPEN_BRACKET )
        if (not r_consume_ws) return false
        if (_scan_pattern_1.scan(_scanner,buffer))
          _add( TokenType.TERM )
          return false
        endIf
        _throw_syntax_error("Target name expected (Global, Default, iOS, ...).")
        return false
      endIf
      if (_scanner.consume('@'))
        _add( TokenType.SYMBOL_AT )
        return false
      endIf
      if (_scanner.consume('+'))
        _add( TokenType.SYMBOL_PLUS )
        return false
      endIf
      if (_scanner.consume('-'))
        _add( TokenType.SYMBOL_MINUS )
        return false
      endIf
      if (_scanner.consume(']'))
        _add( TokenType.SYMBOL_CLOSE_BRACKET )
        return false
      endIf
      if (not r_scan_string) return false
      if (not r_scan_id_term_or_keyword) return false
      _throw_syntax_error
      return false

    method r_tokenize_value->Logical
      if (not r_consume_ws) return false
      if ((not _scanner.has_another))
        halt = true
        return false
      endIf
      line   = _scanner.line
      column = _scanner.column
      _scan_table_0.reset
      contingent
        block n=1
          while (_scanner.has_another(n))
            if (not _scan_table_0.accept(_scanner.peek(n-1)))
              escapeWhile
            endIf
            ++n
          endWhile
          necessary (_scan_table_0.has_product)
          loop (_scan_table_0.match_count) _scanner.read
        endBlock
        which (_scan_table_0.product)
          case 0
            _add( TokenType.SYMBOL_ASTERISK )
            return false
          case 1
            _add( TokenType.SYMBOL_AT )
            return false
          case 2
            _add( TokenType.SYMBOL_CLOSE_PAREN )
            return false
          case 3
            _add( TokenType.SYMBOL_CLOSE_BRACKET )
            return false
          case 4
            _add( TokenType.SYMBOL_COLON )
            return false
          case 5
            _add( TokenType.SYMBOL_EQUALS )
            return false
          case 6
            _add( TokenType.SYMBOL_MINUS )
            return false
          case 7
            _add( TokenType.SYMBOL_OPEN_PAREN )
            return false
          case 8
            _add( TokenType.SYMBOL_OPEN_BRACKET )
            return false
          case 9
            _add( TokenType.SYMBOL_PLUS )
            return false
          case 10
            _add( TokenType.SYMBOL_SLASH )
            return false
          others
            necessary (false)
        endWhich
      endContingent
      if (not r_scan_number) return false
      if (not r_scan_string) return false
      if (not r_scan_id_term_or_keyword) return false
      _throw_syntax_error
      return false

    method r_consume_ws->Logical
      _scan_pattern_2.scan(_scanner)
      return true

    method r_create_identifier->Logical
      if (_scan_pattern_3.scan(_scanner,buffer))
        _add( TokenType.IDENTIFIER )
      endIf
      _throw_syntax_error("Identifier expected.")
      return false

    method r_scan_id_term_or_keyword->Logical
      if (_scan_pattern_3.scan(_scanner,buffer))
        if (_scanner.next_is(':'))
          if (not r_create_id_or_keyword) return false
          _scanner.consume(':')
          _add( TokenType.SYMBOL_COLON )
          if (not r_scan_string) return false
        elseIf ((not _scan_pattern_4.scan(_scanner,buffer)))
          if (not r_create_id_or_keyword) return false
          return false
        endIf
      endIf
      _scan_pattern_4.scan(_scanner,buffer)
      _add( TokenType.TERM )
      return false

    method r_create_id_or_keyword->Logical
      _scan_table_1.reset
      contingent
        necessary (_scan_table_1.accept(forEach in buffer))
        which (_scan_table_1.product)
          case 1
            _add( TokenType.KEYWORD_END_GROUP )
            return true
          case 2
            _add( TokenType.KEYWORD_END_STANDALONE )
            return true
          case 3
            _add( TokenType.KEYWORD_FOLDER )
            return true
          case 4
            _add( TokenType.KEYWORD_GROUP )
            return true
          case 5
            _add( TokenType.KEYWORD_STANDALONE )
            return true
          others
            necessary (false)
        endWhich
      unsatisfied
        _add( TokenType.IDENTIFIER )
      endContingent
      return true

    method r_scan_number->Logical
      if ((not _scanner.has_another))
        return true
      endIf
      if (_scan_pattern_5.scan(_scanner,buffer))
        if (not r_scan_integer) return false
        if (_scan('.'))
          if (not r_scan_integer) return false
        endIf
        _add( TokenType.NUMBER )
        return false
      elseIf (_scan('.'))
        if (not r_scan_integer) return false
        _add( TokenType.NUMBER )
        return false
      else
        return true
      endIf

    method r_scan_integer->Logical
      _scan_pattern_6.scan(_scanner,buffer)
      return true

    method r_scan_string->Logical
      if ((not _scanner.consume('"')))
        return true
      endIf
      while ((_scanner.has_another and (not _scanner.next_is('\n'))))
        ch = _scanner.read
        if ((ch=='"'))
          _add( TokenType.STRING )
          return false
        elseIf (((ch=='\\') and _scanner.has_another))
          ch = _scanner.read
        endIf
        buffer.print(ch)
      endWhile
      _throw_syntax_error("Unterminated string.")
      return false

endClass
